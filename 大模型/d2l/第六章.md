# 图像卷积

## 互相关运算

```python
import torch
from torch import nn
from d2l import torch as d2l
```

```python
def corr2d(X, K):  #@save
    """计算二维互相关运算"""
    h, w = K.shape  # 获取卷积核 K 的高度和宽度
    Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))  # 初始化输出张量 Y
    for i in range(Y.shape[0]):  # 遍历 Y 的每一行
        for j in range(Y.shape[1]):  # 遍历 Y 的每一列
            Y[i, j] = (X[i:i + h, j:j + w] * K).sum()  # 计算 Y[i, j] 的值，即 X 和 K 的二维互相关结果
    return Y
```

```python
X = torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])
K = torch.tensor([[0.0, 1.0], [2.0, 3.0]])
corr2d(X, K)
```

## 卷积层

```python
class Conv2D(nn.Module):
    def __init__(self, kernel_size):
        super().__init__()  # 调用父类的构造函数
        self.weight = nn.Parameter(torch.rand(kernel_size))  # 定义卷积核权重，并转换为可学习的参数
        self.bias = nn.Parameter(torch.zeros(1))  # 定义偏置，并转换为可学习的参数

    def forward(self, x):
        return corr2d(x, self.weight) + self.bias  # 执行前向传播，计算二维互相关结果并加上偏置
```

## 图像中目标的边缘检测

```python
X = torch.ones((6, 8))
X[:, 2:6] = 0
X
```

```python
K = torch.tensor([[1.0, -1.0]])
```

```python
Y = corr2d(X, K)
Y
```

```python
corr2d(X.t(), K)	# X的转置
```

## 学习卷积核

```python
# 构造一个二维卷积层，具有1个输出通道和形状为（1，2）的卷积核
conv2d = nn.Conv2d(1, 1, kernel_size=(1, 2), bias=False)

# 这个二维卷积层使用四维输入和输出格式（批量大小、通道、高度、宽度），
# 其中批量大小和通道数都为1
# 准备输入数据 X 和目标输出数据 Y
X = X.reshape((1, 1, 6, 8))  # 将 X 重新塑形为批量大小为 1，通道数为 1，高度为 6，宽度为 8 的张量
Y = Y.reshape((1, 1, 6, 7))  # 将 Y 重新塑形为批量大小为 1，通道数为 1，高度为 6，宽度为 7 的张量
lr = 3e-2  # 学习率

# 训练循环，迭代10次
for i in range(10):
    Y_hat = conv2d(X)  # 使用卷积层进行前向传播得到预测输出 Y_hat
    l = (Y_hat - Y) ** 2  # 计算预测输出 Y_hat 与目标输出 Y 之间的均方误差损失
    conv2d.zero_grad()  # 清除卷积层的梯度信息
    l.sum().backward()  # 对损失进行反向传播，计算梯度
    conv2d.weight.data[:] -= lr * conv2d.weight.grad  # 根据梯度更新卷积核的权重
    if (i + 1) % 2 == 0:
        print(f'epoch {i+1}, loss {l.sum():.3f}')  # 每两个周期打印一次损失值
```

```python
conv2d.weight.data.reshape((1, 2))  # 将卷积层的权重数据重新塑形为形状为 (1, 2) 的张量
```

# 填充和步幅
## 填充

```python
import torch
from torch import nn


# 为了方便起见，我们定义了一个计算卷积层的函数。
# 此函数初始化卷积层权重，并对输入和输出提高和缩减相应的维数
def comp_conv2d(conv2d, X):
    # 这里的（1，1）表示批量大小和通道数都是1
    X = X.reshape((1, 1) + X.shape)  
    Y = conv2d(X)
    # 省略前两个维度：批量大小和通道
    return Y.reshape(Y.shape[2:])

# 请注意，这里每边都填充了1行或1列，因此总共添加了2行或2列
conv2d = nn.Conv2d(1, 1, kernel_size=3, padding=1)
X = torch.rand(size=(8, 8))
comp_conv2d(conv2d, X).shape    # 返回卷积层处理后的输出形状
```

```python
conv2d = nn.Conv2d(1, 1, kernel_size=(5, 3), padding=(2, 1))
comp_conv2d(conv2d, X).shape
```

## 步幅

```python
conv2d = nn.Conv2d(1, 1, kernel_size=3, padding=1, stride=2)  # 初始化一个卷积层，输入通道数为1，输出通道数为1，内核大小为3x3，填充为1，步幅为2
comp_conv2d(conv2d, X).shape  # 调用 comp_conv2d 函数计算卷积层处理后的输出形状
```

```python
conv2d = nn.Conv2d(1, 1, kernel_size=(3, 5), padding=(0, 1), stride=(3, 4))  # 初始化一个卷积层，输入通道数为1，输出通道数为1，内核大小为(3x5)，填充为(0,1)，步幅为(3,4)
comp_conv2d(conv2d, X).shape  # 调用 comp_conv2d 函数计算卷积层处理后的输出形状
```

# 多输入多输出通道
## 多输入通道

```python
import torch
from d2l import torch as d2l
```

```python
def corr2d_multi_in(X, K):
    # 先遍历“X”和“K”的第0个维度（通道维度），再把它们加在一起
    return sum(d2l.corr2d(x, k) for x, k in zip(X, K))
```

```python
X = torch.tensor([[[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]],
               [[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]]])
K = torch.tensor([[[0.0, 1.0], [2.0, 3.0]], [[1.0, 2.0], [3.0, 4.0]]])

corr2d_multi_in(X, K)
```

## 多输出通道

```python
def corr2d_multi_in_out(X, K):
    # 迭代“K”的第0个维度，每次都对输入“X”执行互相关运算。
    # 最后将所有结果都叠加在一起
    return torch.stack([corr2d_multi_in(X, k) for k in K], 0)
```

```python
K = torch.stack((K, K + 1, K + 2), 0)  # 在第一个维度上堆叠三个张量 K, K+1, K+2
K.shape  # 打印堆叠后的张量 K 的形状
```

```pythn
corr2d_multi_in_out(X, K)
```

## $1\times 1$ 卷积层

```python
def corr2d_multi_in_out_1x1(X, K):
    c_i, h, w = X.shape  # 获取输入张量的通道数、高度和宽度
    c_o = K.shape[0]  # 获取卷积核张量的输出通道数
    X = X.reshape((c_i, h * w))  # 将输入张量重塑为 (c_i, h * w) 的形状(三维降为二维)
    K = K.reshape((c_o, c_i))  # 将卷积核张量重塑为 (c_o, c_i) 的形状
    # 执行全连接层中的矩阵乘法
    Y = torch.matmul(K, X)
    return Y.reshape((c_o, h, w))  # 将结果重塑为 (c_o, h, w) 的形状并返回
```

```python
X = torch.normal(0, 1, (3, 3, 3))  # 创建一个形状为 (3, 3, 3) 的张量 X，从均值为 0，标准差为 1 的正态分布中随机采样
K = torch.normal(0, 1, (2, 3, 1, 1))  # 创建一个形状为 (2, 3, 1, 1) 的张量 K，从均值为 0，标准差为 1 的正态分布中随机采样
```

```python
Y1 = corr2d_multi_in_out_1x1(X, K)
Y2 = corr2d_multi_in_out(X, K)
assert float(torch.abs(Y1 - Y2).sum()) < 1e-6
```

# 汇聚层
## 最大汇聚层和平均汇聚层

```python
import torch
from torch import nn
from d2l import torch as d2l
```

```python
def pool2d(X, pool_size, mode='max'):
    p_h, p_w = pool_size  # 池化窗口的高度和宽度
    Y = torch.zeros((X.shape[0] - p_h + 1, X.shape[1] - p_w + 1))  # 创建用于存储池化结果的张量 Y
    
    # 遍历 Y 的每个元素
    for i in range(Y.shape[0]):
        for j in range(Y.shape[1]):
            if mode == 'max':
                Y[i, j] = X[i: i + p_h, j: j + p_w].max()  # 使用最大池化取池化窗口内的最大值
            elif mode == 'avg':
                Y[i, j] = X[i: i + p_h, j: j + p_w].mean()  # 使用平均池化取池化窗口内的均值
    return Y
```

```python
X = torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])
pool2d(X, (2, 2))
```

```python
pool2d(X, (2, 2), 'avg')
```

## **填充和步幅**

```python
X = torch.arange(16, dtype=torch.float32).reshape((1, 1, 4, 4))#（批量大小、通道、高度、宽度）
X
```

```python
# 创建一个最大池化层，池化窗口大小为 3x3，默认步幅为窗口大小
pool2d = nn.MaxPool2d(3)
pool2d(X)
```

```python
pool2d = nn.MaxPool2d(3, padding=1, stride=2)  # 创建一个最大池化层，窗口大小为3x3，填充为1，步幅为2
pool2d(X)  # 对输入张量X进行最大池化操作
```

```python
pool2d = nn.MaxPool2d((2, 3), stride=(2, 3), padding=(0, 1))  # 创建一个最大池化层，窗口大小为2x3，填充为(0, 1)，步幅为(2, 3)
pool2d(X)  # 对输入张量X进行最大池化操作
```

## 多个通道

```python
X = torch.cat((X, X + 1), 1)  # 在第1维度（列维度）上连接张量X和X + 1
X  # 返回连接后的张量X
```

```python
pool2d = nn.MaxPool2d(3, padding=1, stride=2)  # 创建一个最大池化层，窗口大小为3x3，填充为1，步幅为2
pool2d(X)  # 对输入张量X进行最大池化操作
```

# 卷积神经网络（LeNet）
## LeNet

```python
import torch
from torch import nn
from d2l import torch as d2l

net = nn.Sequential(
    nn.Conv2d(1, 6, kernel_size=5, padding=2), nn.Sigmoid(),  # 第一层卷积层：输入通道1，输出通道6，卷积核大小5x5，填充2，使用Sigmoid激活函数
    nn.AvgPool2d(kernel_size=2, stride=2),  # 第一层平均池化层：池化窗口大小2x2，步幅2
    nn.Conv2d(6, 16, kernel_size=5), nn.Sigmoid(),  # 第二层卷积层：输入通道6，输出通道16，卷积核大小5x5，无填充，使用Sigmoid激活函数
    nn.AvgPool2d(kernel_size=2, stride=2),  # 第二层平均池化层：池化窗口大小2x2，步幅2
    nn.Flatten(),  # 展平操作，将多维张量展平为一维
    nn.Linear(16 * 5 * 5, 120), nn.Sigmoid(),  # 全连接层1：输入维度为16x5x5，输出维度为120，使用Sigmoid激活函数
    nn.Linear(120, 84), nn.Sigmoid(),  # 全连接层2：输入维度为120，输出维度为84，使用Sigmoid激活函数
    nn.Linear(84, 10)  # 全连接层3：输入维度为84，输出维度为10，无激活函数（输出层）
)
```

```python
X = torch.rand(size=(1, 1, 28, 28), dtype=torch.float32)  # 创建一个随机张量作为输入，形状为(1, 1, 28, 28)

for layer in net:
    X = layer(X)
    print(layer.__class__.__name__, 'output shape: \t', X.shape)
```

## 模型训练

```python
batch_size = 256  # 设置批量大小为256，即每个批次包含256个样本
train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size=batch_size)  # 使用d2l.load_data_fashion_mnist函数加载Fashion-MNIST数据集，并分别得到训练集和测试集的迭代器
```

```python
def evaluate_accuracy_gpu(net, data_iter, device=None): #@save
    """使用GPU计算模型在数据集上的精度"""
    if isinstance(net, nn.Module):
        net.eval()  # 设置为评估模式
        if not device:
            device = next(iter(net.parameters())).device
    # 正确预测的数量，总预测的数量
    metric = d2l.Accumulator(2)  # 创建一个累加器，用于存储正确预测的数量和总预测的数量
    with torch.no_grad():
        for X, y in data_iter:
            if isinstance(X, list):
                # 对于BERT微调所需的输入（稍后会介绍），将列表中的每个张量移动到指定的设备上
                X = [x.to(device) for x in X]
            else:
                X = X.to(device)  # 将输入张量移动到指定的设备上
            y = y.to(device)  # 将标签张量移动到指定的设备上
            # 计算当前批次的预测精度并累加到metric中
            metric.add(d2l.accuracy(net(X), y), y.numel())
    return metric[0] / metric[1]  # 返回模型在数据集上的精度，即正确预测的比例
```

```python
#@save
def train_ch6(net, train_iter, test_iter, num_epochs, lr, device):
    """用GPU训练模型(在第六章定义)"""
    # 初始化模型参数
    def init_weights(m):
        if type(m) == nn.Linear or type(m) == nn.Conv2d:
            nn.init.xavier_uniform_(m.weight)
    net.apply(init_weights)  # 应用初始化函数到模型的每一层
    print('training on', device)
    net.to(device)  # 将模型移动到指定的设备（如GPU）
    optimizer = torch.optim.SGD(net.parameters(), lr=lr)  # 定义优化器
    loss = nn.CrossEntropyLoss()  # 定义损失函数
    animator = d2l.Animator(xlabel='epoch', xlim=[1, num_epochs],
                            legend=['train loss', 'train acc', 'test acc'])  # 创建动画对象用于可视化
    timer, num_batches = d2l.Timer(), len(train_iter)
    for epoch in range(num_epochs):
        # 训练损失之和，训练准确率之和，样本数
        metric = d2l.Accumulator(3)
        net.train()  # 设置模型为训练模式
        for i, (X, y) in enumerate(train_iter):
            timer.start()
            optimizer.zero_grad()  # 梯度清零
            X, y = X.to(device), y.to(device)  # 将数据移动到指定设备（如GPU）
            y_hat = net(X)  # 前向传播计算预测值
            l = loss(y_hat, y)  # 计算损失
            l.backward()  # 反向传播计算梯度
            optimizer.step()  # 更新模型参数
            with torch.no_grad():
                metric.add(l * X.shape[0], d2l.accuracy(y_hat, y), X.shape[0])  # 累加训练损失、准确率和样本数
            timer.stop()
            train_l = metric[0] / metric[2]  # 平均训练损失
            train_acc = metric[1] / metric[2]  # 平均训练准确率
            if (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1:
                animator.add(epoch + (i + 1) / num_batches,
                             (train_l, train_acc, None))  # 更新动画显示训练指标
        test_acc = evaluate_accuracy_gpu(net, test_iter)  # 在测试集上评估模型精度
        animator.add(epoch + 1, (None, None, test_acc))  # 更新动画显示测试精度
    print(f'loss {train_l:.3f}, train acc {train_acc:.3f}, '
          f'test acc {test_acc:.3f}')  # 打印最终的损失和精度
    print(f'{metric[2] * num_epochs / timer.sum():.1f} examples/sec '
          f'on {str(device)}')  # 打印每秒处理的样本数
```

```python
lr, num_epochs = 0.9, 10  # 学习率为0.9，训练轮数为10次
train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())  # 使用GPU训练模型，调用train_ch6函数进行训练
```


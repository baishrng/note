# 提取环境违法信息爬虫程序

```python
import requests
from bs4 import BeautifulSoup
import re
from random import randint, choice
from time import sleep
from openpyxl import load_workbook


def get_headers() -> dict:
    # 谷歌
    headers1 = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/127.0.0.0 Safari/537.36",
        "Cookie": "Secure; _gscu_2139452564=307945618ay86f20; _gscu_1156254399=30794573bfx1zk19; 267_vq=6; sl-session=8iO2XAJhMGcCuNNec0PzKw==; arialoadData=true; Hm_lvt_5d200531dfa2d9aeca26825ed0fb8511=1731137411,1731158047,1731204227,1731220775; HMACCOUNT=AA55FD0EF2471983; _gscbrs_2139452564=1; _gscs_2139452564=31220775jdzmyd92|pv:3; Hm_lpvt_5d200531dfa2d9aeca26825ed0fb8511=1731220839",
        "Accept-language": "zh-CN,zh;q=0.9,en-US;q=0.8,en;q=0.7",
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7"}

    # edge
    headers2 = {
        "User-Agent" : "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36 Edg/130.0.0.0",
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7",
        "Cookie": "_gscu_2139452564=31033728i3g8ln11; sl-session=k+tEStpoMWf0ZBfPBE7jew==; arialoadData=true; _gscbrs_2139452564=1; _gscs_2139452564=31219712cehy3298|pv:1; Hm_lvt_5d200531dfa2d9aeca26825ed0fb8511=1731072595,1731146746,1731204955,1731219712; Hm_lpvt_5d200531dfa2d9aeca26825ed0fb8511=1731219712; HMACCOUNT=212B77FC1785264D",
        "Accept-Language": "zh-CN,zh;q=0.9,en-GB;q=0.8,en-US;q=0.7,en;q=0.6"
    }

    # 火狐
    headers3 = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:127.0) Gecko/20100101 Firefox/127.0",
        "Cookie": "sl-session=6K1WBlalMWdXCQ/oiYl4Ew==; _gscu_2139452564=31220439i4q3gu27; _gscs_2139452564=312204393rfbqb27|pv:1; _gscbrs_2139452564=1; arialoadData=true; ariawapChangeViewPort=true; Hm_lvt_5d200531dfa2d9aeca26825ed0fb8511=1731220445; Hm_lpvt_5d200531dfa2d9aeca26825ed0fb8511=1731220445; HMACCOUNT=A32F731DA407C040",
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8",
        "Accept-Language": "zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2"
    }

    return choice([headers1, headers2, headers3])

def get_all_link(url: str) -> list:
    headers = get_headers()
    r = requests.get(url, headers=headers, verify=False)
    # print(r.content.decode('utf-8'))

    soup = BeautifulSoup(r.content, 'html.parser')
    # print(soup.prettify())

    link_list = list()

    a_list = soup.find_all(['a'])

    for a in a_list:
        # print(a)
        href = a.get("href")
        title = a.text
        title = title.replace(" ", "")

        if href is not None and title is not None:
            if (("毕环" in title and "罚" in title)
                    and "不" not in title):
                if href not in link_list:
                    print(href + " " + title)
                    link_list.append(href)

    return link_list

def get_info(url: str) -> dict:
    headers = get_headers()
    try:
        r = requests.get(url, headers=headers, verify=False)
    except Exception as e:
        print(e)
        return None

    if r.status_code != 200:
        return None

    soup = BeautifulSoup(r.content, 'lxml')
    # print(soup.prettify())

    info_dict = dict()

    title = soup.find(name='div', attrs={'class':'DocTitle'})
    title_text = title.text
    title_texts = title_text.split(' ')
    title_texts = [text for text in title_texts if text != '']
    # print(title_texts)

    # 行政处罚决定书编号
    if not info_dict.get('行政处罚决定书编号'):
        if len(title_texts) > 1:
            info_dict["行政处罚决定书编号"] = title_texts[1]

    # 处罚企业名称
    if not info_dict.get('处罚企业名称'):
        if len(title_texts) > 2:
            info_dict["处罚企业名称"] = title_texts[-1]

    ps = soup.find_all(['p', 'h1', 'h3', 'h4'])
    text_list = []
    for p in ps:
        text = p.text
        text = text.replace(' ', "")
        text = text.strip()
        text_list.append(text)
        # print(p.text)
    #
    # print("---------------------------------------------------------")

    for i in range((len(text_list))):
        # 行政处罚决定书编号
        if "德环罚" in text_list[i].strip():
            start_index = text_list[i].find("德环罚")
            end_index = text_list[i].find("号", start_index)
            if not info_dict.get('行政处罚决定书编号'):
                info_dict["行政处罚决定书编号"] = text_list[i][start_index:end_index + 1]

        # 处罚企业名称
        if ('当事人名称' in text_list[i] or "当事人" in text_list[i]
                or "名称" in text_list[i]):
            if not info_dict.get('处罚企业名称'):
                info_dict["处罚企业名称"] = text_list[i]

        if '统一社会信用代码' in text_list[i]:
            if not info_dict.get('处罚企业名称'):
                info_dict["处罚企业名称"] = text_list[i - 1]

        # 违法事实
        if "环境违法行为和证据" in text_list[i] or "违法事实和相关证据" in text_list[i]:
            info = text_list[i + 1]
            if info.endswith("环境违法行为：") or info.endswith("经查发现：") or info.endswith("以下行为："):
                info = text_list[i + 2]
            if not info_dict.get('违法事实'):
                info_dict["违法事实"] = info

        if "环境违法事实、证据" in text_list[i] or "违法事实和相关证据" in text_list[i]:
            info = text_list[i + 1]
            if info.endswith("环境违法行为：") or info.endswith("经查发现：") or info.endswith("以下行为："):
                info = text_list[i + 2]
            if not info_dict.get('违法事实'):
                info_dict["违法事实"] = info

        if text_list[i].startswith("以上事实"):
            if not info_dict.get('违法事实'):
                info_dict["违法事实"] = text_list[i - 1]

        if text_list[i].endswith("违法行为："):
            info = text_list[i + 1]
            if not info_dict.get('违法事实'):
                info_dict["违法事实"] = info

        # 违反生态环境法律条款
        if '违反了《' in text_list[i]:
            info = text_list[i]
            if not info_dict.get('违反生态环境法律条款'):
                info_dict["违反生态环境法律条款"] = info
            else:
                info = " +++ " + info
                info_dict["违反生态环境法律条款"] += info

        if '涉嫌违反《' in text_list[i]:
            info = text_list[i]
            if not info_dict.get('违反生态环境法律条款'):
                info_dict["违反生态环境法律条款"] = info
            else:
                info = " +++ " + info
                info_dict["违反生态环境法律条款"] += info

        if '违反了:《' in text_list[i]:
            info = text_list[i]
            if not info_dict.get('违反生态环境法律条款'):
                info_dict["违反生态环境法律条款"] = info
            else:
                info = " +++ " + info
                info_dict["违反生态环境法律条款"] += info

        if '违反了: 《' in text_list[i]:
            info = text_list[i]
            if not info_dict.get('违反生态环境法律条款'):
                info_dict["违反生态环境法律条款"] = info
            else:
                info = " +++ " + info
                info_dict["违反生态环境法律条款"] += info

        if '违反《' in text_list[i]:
            info = text_list[i]
            if not info_dict.get('违反生态环境法律条款'):
                info_dict["违反生态环境法律条款"] = info
            else:
                info = " +++ " + info
                info_dict["违反生态环境法律条款"] += info

        # 处罚依据
        # if '行政处罚的依据、种类' in text_list[i] and '《' in text_list[i + 1]:
        #     info = text_list[i+1]
        #     if not info_dict.get('处罚依据'):
        #         info_dict["处罚依据"] = info
        #
        # if '行政处罚的依据' in text_list[i] and '《' in text_list[i + 1]:
        #     info = text_list[i+1]
        #     if not info_dict.get('处罚依据'):
        #         info_dict["处罚依据"] = info

        # if text_list[i].startswith('依据《') or text_list[i].startswith('根据《'):
        #     info = text_list[i]
        #     if not info_dict.get('处罚依据'):
        #         info_dict["处罚依据"] = info

        if '依据《' in text_list[i] or '根据《' in text_list[i]:
            info = text_list[i]
            if not info_dict.get('处罚依据'):
                info_dict["处罚依据"] = info
        # if '依据：' in text_list[i] and "《" in text_list[i + 1]:
        #     info = text_list[i + 1]
        #     if not info_dict.get('处罚依据'):
        #         info_dict["处罚依据"] = info

        # 行政处罚结果
        # if "作出如下决定" in text_list[i]:
        #     if not info_dict.get('行政处罚结果'):
        #         info_dict["行政处罚结果"] = text_list[i + 1]
        #
        # if "作出下行政处罚：" in text_list[i]:
        #     if not info_dict.get('行政处罚结果'):
        #         info_dict["行政处罚结果"] = text_list[i+1]
        #
        # if "如下行政处罚：" in text_list[i]:
        #     if not info_dict.get('行政处罚结果'):
        #         info_dict["行政处罚结果"] = text_list[i+1]
        #
        # if "作出如下处理决定：" in text_list[i]:
        #     if not info_dict.get('行政处罚结果'):
        #         info_dict["行政处罚结果"] = text_list[i+1]
        #
        # if "履行方式和期限" in text_list[i] and "元" in text_list[i + 1]:
        #     index = text_list[i + 1].find("元")
        #     if not info_dict.get('行政处罚结果'):
        #         info_dict["行政处罚结果"] = text_list[i+1][:index + 1]

        if "罚" in text_list[i] and "元" in text_list[i]:
            start_index = text_list[i].rfind("罚")
            # end_index = text_list[i].rfind("元")
            if start_index != -1:
                info_dict["行政处罚结果"] = text_list[i][start_index:]

        if "总计" in text_list[i] and "元" in text_list[i]:
            start_index = text_list[i].find("总计")
            end_index = text_list[i].rfind("元")
            if start_index < end_index:
                info_dict["行政处罚结果"] = text_list[i][start_index:end_index + 1]

        # 发布时间
        if '毕节市生态环境局' in text_list[i] or "德宏州生态环境局" in text_list[i]:
            try:
                date = text_list[i + 1]
            except IndexError:
                return None
            date = date.replace(" ", "")
            date = date.replace("\u00A0", "")
            pattern = r'^[0-9]{4}年[0-9]{1,2}月[0-9]{1,2}日$'
            if not re.match(pattern, date):
                continue
            if not info_dict.get('发布时间'):
                info_dict["发布时间"] = date
    info_dict['url'] = url
    return info_dict


def append_to_excel(filename: str, info_dicts: list, append_row: int):
    # 读取已有文件
    wb = load_workbook(filename)

    # 选择工作表
    ws = wb["行政处罚"]

    # 获取文件中以存在的 行政处罚决定书编号
    column = ws['G']
    decision_no_list = [column[i].value for i in range(1, append_row)]

    for i in range(len(info_dicts)):
        info_dict = info_dicts[i]

        # 判断数据是否已经存在
        # if (info_dict.get("行政处罚决定书编号", "") != ""
        #         and info_dict.get("行政处罚决定书编号", "") in decision_no_list):
        #     continue

        # 定位需要插入数据的位置
        new_cell0 = f"B{append_row}"
        new_cell1 = f"C{append_row}"
        new_cell2 = f"D{append_row}"
        new_cell3 = f"E{append_row}"
        new_cell4 = f"F{append_row}"
        new_cell5 = f"G{append_row}"
        new_cell6 = f"H{append_row}"
        new_cell7 = f"I{append_row}"
        new_cell8 = f"J{append_row}"

        # 将数据放在准备的位置
        ws[new_cell0] = info_dict.get("业务类型","")
        ws[new_cell1] = info_dict.get("违法事实", "")
        ws[new_cell2] = info_dict.get("违反生态环境法律条款", "")
        ws[new_cell3] = info_dict.get("处罚依据", "")
        ws[new_cell4] = info_dict.get("行政处罚结果", "")
        ws[new_cell5] = info_dict.get("行政处罚决定书编号", "")
        ws[new_cell6] = info_dict.get("发布时间", "")
        ws[new_cell7] = info_dict.get("处罚企业名称", "")
        ws[new_cell8] = info_dict.get("url", "")

        append_row += 1
        print(info_dict.get("行政处罚决定书编号", "") + " " + "完成")

    # 保存文件
    wb.save("D:\\work\\语义库内容收集表格1103.xlsx")

    print("所有完成")


def data_handle(info_dict:dict) -> dict:
    # 行政处罚决定书编号
    if info_dict.get('行政处罚决定书编号'):
        info = info_dict.get('行政处罚决定书编号')
        index = info.find("号")
        if index != -1:
            info_dict["行政处罚决定书编号"] = info[:index + 1]

    # 处罚企业名称
    if info_dict.get('处罚企业名称'):
        info = info_dict.get('处罚企业名称')
        index = info.find("：")
        if index != -1 and info[-1] != "：":
            info = info[index+1:]
        info = info.replace("：", "")
        info_dict["处罚企业名称"] = info.strip()

    # 行政处罚结果
    if info_dict.get('行政处罚结果'):
        info = info_dict.get('行政处罚结果').replace("整", "")
        info = info.replace("。", "")
        info = info.replace("人民币", "")
        info = info.replace(".00","")
        info = info.replace("总计","罚款")
        info = info.replace("金额","")
        info = info.replace(' ',"")
        info = info.replace(',',"")
        info = info.replace('，',"")

        pattern = "[0-9]+\.?[0-9]*"
        moneys = re.findall(pattern, info)
        if moneys:
            info = "罚款" + moneys[0] + "元"

        index = info.find("罚款")
        if index != -1:
            info = info[index:]
        index = info.rfind("元")
        if index != -1:
            info = info[:index + 1]

        info_dict["行政处罚结果"] = info

    # 处罚依据
    if info_dict.get('处罚依据'):
        info = info_dict.get('处罚依据')
        index = info.find("依据《")
        if index != -1:
            info = info[index+2:]
            info_dict["处罚依据"] = info
        index = info.find("根据《")
        if index != -1:
            info = info[index+2:]
            info_dict["处罚依据"] = info

        index = info.rfind("”")
        if index != -1:
            info = info[:index+1]

        info_dict["处罚依据"] = info


    # 违反生态环境法律条款
    if info_dict.get('违反生态环境法律条款'):
        info = info_dict.get('违反生态环境法律条款')
        index = info.find("违反了《")
        info = info[index+3:]

        index = info.rfind("”")
        if index != -1:
            info = info[:index + 1]
        else:
            index = info.rfind("）")
            if index != -1:
                info = info[:index + 1]
        info_dict["违反生态环境法律条款"] = info

    # 业务类型
    if "水污染" in info_dict.get('违反生态环境法律条款',""):
        info_dict["业务类型"] = "水"
    if "大气污染" in info_dict.get('违反生态环境法律条款', ""):
        info_dict["业务类型"] = "大气"
    if "固体废物污染" in info_dict.get('违反生态环境法律条款',""):
        info_dict["业务类型"] = "固废"
    if "噪声污染" in info_dict.get('违反生态环境法律条款',""):
        info_dict["业务类型"] = "噪声"
    if "排污许可" in info_dict.get('违反生态环境法律条款',""):
        info_dict["业务类型"] = "排污许可证"


    return info_dict

if __name__ == "__main__":
    filename = "D:\\work\\语义库内容收集表格1103.xlsx"
    pages = ["index_3.html"]
    page_url = "https://www.bijie.gov.cn/zwgk/zdlyxxgk/xzcf2023/"
    url = ""
    start_row = 2
    info_count = 0  # 信息的数量
    code_list = list()  # 行政处罚决定书编号 列表

    info_list = []
    for page in pages:
        page = page_url + page

        all_link = get_all_link(page)  # 获取页面中所有的可用链接

        for link in all_link:
            # link = url + link[2:]

            info_dict = get_info(link)
            if not info_dict:
                continue

            # 去重
            if info_dict.get("行政处罚决定书编号"):
                code = info_dict.get("行政处罚决定书编号")
                if code not in code_list:
                    code_list.append(code)
                else:
                    continue

            # 删除无用数据
            if len(info_dict) < 3:
                continue

            # 输出查看
            for key, value in info_dict.items():
                print(key)
                print(value)
                print()
            data_handle(info_dict)
            info_list.append(info_dict)
            sleep(randint(3, 5))

        append_to_excel(filename, info_list, start_row)
        info_count += len(info_list)
        start_row += len(info_list)
        info_list.clear()
        sleep(randint(3, 5))
        print(f"页面 {page} 完成")

    print(f"总共 {info_count} 条数据")
```

## 使用DrissionPage

```python
from DrissionPage import Chromium
from typing import List, Optional
import re
from time import sleep
from random import uniform

class Setting:
    # 目录页的url
    page_url = 'https://zs.kaipuyun.cn/s?searchWord=%25E4%25B8%25BD%25E7%258E%25AF%25E7%25BD%259A&column=%25E5%2585%25A8%25E9%2583%25A8&pageSize=10&pageNum=0&siteCode=5307000001&sonSiteCode=&checkHandle=1&searchSource=0&areaSearchFlag=0&secondSearchWords=&topical=&docName=&label=&countKey=0&uc=0&left_right_index=0&searchBoxSettingsIndex=&isSecondSearch=undefined&manualWord=%25E7%2594%259F%25E6%2580%2581%25E7%258E%25AF%25E5%25A2%2583&orderBy=0&startTime=&endTime=&timeStamp=0&strFileType=&wordPlace=0'
    page_number = 4     # 总页数
    url_title_keywords = '丽环罚'  # url中包含的关键字，根据这个来筛选目标url

class Crawler:
    def __init__(self):
        self.browser = Chromium()
        self.tab = self.browser.latest_tab
        self.setting = Setting()

    def get_all_url(self, page_url: str) -> List[str]:
        self.tab.get(page_url)
        self.tab.wait.doc_loaded()

        urls = set()    # 设置成集合，去掉重复项

        for i in range(self.setting.page_number):
            self.tab.wait(2.5, 4)
            print(f'第{i+1}页')

            url_eles = self.tab.eles('@@tag():a@@text():'+self.setting.url_title_keywords)
            for url_ele in url_eles:
                urls.add(url_ele.link)
                print(url_ele.text + " " + url_ele.link)    # 输出url的标题和url，检验效果

            self.tab.scroll.to_bottom()
            self.tab.actions.click('@text():下一页')

        return list(urls)


    def get_a_url_text(self, url: str) -> Optional[str]:
        self.tab.get(url)

        text = ''
        eles = self.tab.eles('@@tag():p')
        for ele in eles:
            text += ele.text + '\n'

        # 将文本从日期处截断
        try:
            pattern = r'^[0-9]{4}年[0-9]{1,2}月[0-9]{1,2}日$'
            time = re.findall(pattern, text, re.M)[-1]
            index = text.find(time)
            text = text[:index + len(time)]
            print(text+'\n')    # 输出文本，检验效果
        except IndexError:
            pass

        return text

    def get_urls_text(self, urls: List[str]) -> List[str]:
        texts = list()
        for url in urls:
            sleep(uniform(2.5, 3.6))
            texts.append(self.get_a_url_text(url))
        return texts

setting = Setting()
crawler = Crawler()
try:
    urls = crawler.get_all_url(setting.page_url)
    texts = crawler.get_urls_text(urls)
    print(len(texts))
except Exception as e:
    print(e)
```


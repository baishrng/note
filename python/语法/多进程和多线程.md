## 多进程

### 1、创建进程

[创建线程](https://so.csdn.net/so/search?q=创建线程&spm=1001.2101.3001.7020)的方法有两种，一种是直接使用 `multiprocessing` 模块里面的类来进行创建，一种是继承 `multiprocessing` 模块的类写一个类来对线程进行创建。

#### 1.1直接创建

我们可以通过直接从 `multiprocessing.Process` 继承创建一个新的子类，并实例化后调用 `start()` 方法启动新进程，即相当于它调用了进程的 `run()` 方法。

该方法的参数如下：

```python
Process(group=None, target=None, name=None, args=(), kwargs={}, *, daemon=None)
```

`target `指要创建的进程的方法名，`name `指给此进程命名，命名后可以调用 `multiprocessing.current_process().name `方法输出该进程的名字， `args/kwargs` 指 `target `指向的方法需要传递的参数，必须是元组形式，如果只有一个参数，需要以添加逗号。

示例：

假如我们创建两个进程，一个每隔两秒对传入的数加2，一个每隔1秒对传入的数加1

```python
import multiprocessing
from multiprocessing import Process
import time


def process1(num):
    while True:
        num += 2
        print('{} is running >> {}'.format(multiprocessing.current_process().name, num))
        time.sleep(2)


if __name__ == '__main__':
    # 设置进程
    new_pro = Process(target=process1, name='Add2', args=(100,))
    # 进程开始
    new_pro.start()

    n = 0
    while True:
        n += 1
        print('{} is running >> {}'.format(multiprocessing.current_process().name, n))
        time.sleep(1)
```

结果：

```
MainProcess is running >> 1
MainProcess is running >> 2
Add2 is running >> 102
MainProcess is running >> 3
MainProcess is running >> 4
Add2 is running >> 104
MainProcess is running >> 5
MainProcess is running >> 6
Add2 is running >> 106
```

注意使用多进程的时候需要特别注意，必须要有` if __name__ == '__main__:'`， 该语句下的代码相当于主进程，没有该语句会报错。

简单解释下上述内容，由于Python运行过程中，新创建进程后，进程会导入正在运行的文件，即如果没有 `if __name__ == '__main__':`，代码在运行到 new_pro 时，新的进程会重新读入代码，新进程认为其是要再次运行的代码，这是子进程又一次运行到 new_pro ，但是在 `multiprocessing.Process` 的源码中是对子进程再次产生子进程是做了限制的，是不允许的，于是便会出现错误。

#### 1.2 继承创建

即继承Process来自定义进程类，重写run方法。

示例：

```python
import multiprocessing
from multiprocessing import Process
import time


# 继承进程类
class MyProcess(Process):
    def __init__(self, num:int):
        super().__init__()  # 必须调用父类的初始化方法
        self.num = num

    def run(self) -> None:
        while True:
            self.num += 2
            print('{} is running >> {}'.format(multiprocessing.current_process().name, self.num))
            time.sleep(2)


if __name__ == '__main__':
    new_pro = MyProcess(100)
    # 设置进程名字
    new_pro.name = "Add2"
    new_pro.start()

    n = 0
    while True:
        n += 1
        print('{} is running >> {}'.format(multiprocessing.current_process().name, n))
        time.sleep(1)
```

结果：

```
MainProcess is running >> 1
MainProcess is running >> 2
Add2 is running >> 102
MainProcess is running >> 3
MainProcess is running >> 4
Add2 is running >> 104
MainProcess is running >> 5
```

---

### 2、守护进程和join()方法

如果当前python进程是守护进程，那么意味着这个进程是“不重要”的，“不重要”意味着如果他的主进程结束了但该守护进程没有运行完，守护进程就会被强制结束。如果进程是非守护进程，那么父进程只有等到非守护进程运行完毕后才能结束。如果需要设置一个进程为守护进程，只需要将其 `daemon `参数设置为 True 即可。

示例：

```python
import multiprocessing
from multiprocessing import Process
import time


def process1(num):
    while True:
        num += 1
        print('{} is running >> {}'.format(multiprocessing.current_process().name, num))
        time.sleep(1)


def process2(num):
    while True:
        num += 2
        print('{} is running >> {}'.format(multiprocessing.current_process().name, num))
        time.sleep(2)


if __name__ == '__main__':
    new_pro1 = Process(target=process1, name='Add1', args=(100,))
    new_pro1.daemon = True
    new_pro1.start()
    new_pro1.join(3)

    new_pro2 = Process(target=process2, name='Add2', args=(1,))
    new_pro2.daemon = True
    new_pro2.start()

    time.sleep(3)
    print('{} Already Endding'.format(multiprocessing.current_process().name))
```

结果：

```
Add1 is running >> 101
Add1 is running >> 102
Add1 is running >> 103
Add2 is running >> 3
Add1 is running >> 104
Add1 is running >> 105
MainProcess Already Endding
```

以上结果显示，前三秒钟，Add1 阻塞了所有的进程，包括主进程，过了三秒后，阻塞结束，再过三秒后，主进程运行结束，由于没有了非守护进程，两个守护进程没有了守护的意义，故程序结束。

`join` 方法的参数如下：

```
join([timeout])
```

如果可选参数 `timeout` 是 `None` （默认值），则该方法将阻塞其他所有进程（包括主进程），直到调用 `join()` 方法的进程终止。如果 `timeout` 是一个正数，它最多会阻塞 `timeout` 秒。

---

### 3、进程锁

进程锁与线程锁不能说相似吧，也就是一模一样了 ，只不过是库变了一下，甚至连API都一样，仅仅是使用时由 `lock = threading.Lock()` 变为了 `lock = multiprocessing.Lock()` 等，具体的使用可以看虾米那看下面多线程中的线程锁。

---

### 4、进程通信

进程之间不共享数据的。如果进程之间需要进行通信，则要用到 `Queue` 模块或者 `Pipe` 模块来实现。

例如，我有两个进程，一个进程会产生一个随机数，另一个进程需要将上一个进程产生的随机数进行加1操作，我想大部分人都是想的是用全局变量来进行操作，操作如下：

```python
from multiprocessing import Process
import random

data = 0
def process1():
    global data
    data = random.random()
    print('产生的data = {}'.format(data))

def process2():
    global data
    data = data + 1
    print('加一后的data = {}'.format(data))

if __name__ == '__main__':
    new_pro1 = Process(target=process1)
    new_pro1.start()

    new_pro2 = Process(target=process2)
    new_pro2.start()
```

结果：

```
产生的data = 0.20874025919433448
加一后的data = 1
```

很明显没有达到想要的目的。那么，为什么会这样呢？那是因为每个子进程享有独立的内存空间，接收进程产生的数据不能马上同步到转发进程中。所以，我们接下来讲讲使用 `Queue` 模块或者 `Pipe` 模块进行进程间的通信。（好像这样可以实现。但可能是因为进程少的原因吧）

#### 4.1 Queue

`Queue` 模块中最常用的方法就是 `put` 以及 `get` 方法了，一个是将数据放入队列中，一个是将数据从队列中取出。其他诸如 `empty(),full()` 等方法可在多线程的线程同步中找到。

上述方法如下：

```
multiprocessing.Queue([maxsize])
```

`maxsize` 参数可选，如果填入了参数，则申请一个 `maxsize` 大小的队列。

```
put(obj[, block[, timeout]])
```

将 obj 放入队列。如果可选参数 block 是 True (默认值) 而且 timeout 是 None (默认值), 将会阻塞当前进程，直到有空的缓冲槽。如果 timeout 是正数，将会在阻塞了最多 timeout 秒之后还是没有可用的缓冲槽时抛出 queue.Full 异常。反之 (block 是 False 时)，仅当有可用缓冲槽时才放入对象，否则抛出 queue.Full 异常 (在这种情形下 timeout 参数会被忽略)。

```
get([block[, timeout]])
```

从队列中取出并返回对象。如果可选参数 block 是 True (默认值) 而且 timeout 是 None (默认值), 将会阻塞当前进程，直到队列中出现可用的对象。如果 timeout 是正数，将会在阻塞了最多 timeout 秒之后还是没有可用的对象时抛出 queue.Empty 异常。反之 (block 是 False 时)，仅当有可用对象能够取出时返回，否则抛出 queue.Empty 异常 (在这种情形下 timeout 参数会被忽略)。

使用该模块将上面的例子写为进程间的通信后改为：

```python
from multiprocessing import Process, Queue
import random

def process1(q):
    data = random.random()
    # 将数据放入队列中
    q.put(data)
    print('产生的data = {}'.format(data))

def process2(q):
    # 从队列中得到数据
    data = q.get()
    data = data + 1
    print('加一后的data = {}'.format(data))

if __name__ == '__main__':
    # 初始化队列
    queue = Queue()
    new_pro1 = Process(target=process1, args=(queue,))
    new_pro1.start()

    new_pro2 = Process(target=process2, args=(queue,))
    new_pro2.start()
```

结果：

```
产生的data = 0.35837061398572
加一后的data = 1.35837061398572
```

**注意：**任何使用队列的时候，你都要确保在进程`join`之前，所有存放到队列中的项将会被其他进程、线程完全消费。否则不能保证这个写过队列的进程可以正常终止。

下面是一个会导致死锁的例子:

```python
from multiprocessing import Process, Queue

def f(q):
    q.put('X' * 1000000)

if __name__ == '__main__':
    queue = Queue()
    p = Process(target=f, args=(queue,))
    p.start()
    p.join()                    # this deadlocks
    obj = queue.get()
```

#### 4.2 Pipe

如果你创建了很多个子进程，那么其中任何一个子进程都可以对Queue进行存（put）和取（get）。但Pipe不一样，Pipe只提供两个端点，只允许两个子进程进行存（send）和取（recv）。也就是说，Pipe实现了两个子进程之间的通信。

将上面的例子使用 Pipe 进行改动后，程序如下：

```python
from multiprocessing import Process, Pipe
import random

def process1(conn_1):
    data = random.random()
    # 将数据放入管道的一端
    conn_1.send(data)
    print('产生的data = {}'.format(data))

def process2(conn_2):
    # 从管道另一端得到数据
    data = conn_2.recv()
    data = data + 1
    print('加一后的data = {}'.format(data))

if __name__ == '__main__':
    # 初始化管道的两端
    conn_1, conn_2 = Pipe()
    new_pro1 = Process(target=process1, args=(conn_1,))
    new_pro1.start()

    new_pro2 = Process(target=process2, args=(conn_2,))
    new_pro2.start()
```

结果：

```
产生的data = 0.31878883290075943
加一后的data = 1.3187888329007595
```

---

### 5、进程数据共享

上面的进程通信中， `Queue` 要求要先进先出， `Pipe` 只能够实现两个进程的存取，如果要一个数据拿给所有进程使用且不要求先进先出，那该使用什么呢？这就需要用到进程间的数据共享了。

#### 5.1 Value

`Value` 数据共享类最多能够共享一个值，该函数的参数如下：

```
Value(typecode_or_type, args, lock=True)
```

上述方法中，参数 typecode_or_type 定义 ctypes() 对象的类型，可以传 Type code 或 C Type，具体对照表见下文。args 传递给 typecode_or_type 构造函数的参数，lock 默认为True，创建一个互斥锁来限制对Value对象的访问，如同传入一个锁，如Lock或RLock的实例，将用于同步。如果传入False，Value的实例就不会被锁保护，它将不是进程安全的。

| Type code | C Type             | Python Type       | Minimum size in bytes |
| --------- | ------------------ | ----------------- | --------------------- |
| `c`       | char               | character         | 1                     |
| `'b'`     | signed char        | int               | 1                     |
| `'B'`     | unsigned char      | int               | 1                     |
| `'u'`     | Py_UNICODE         | Unicode character | 2                     |
| `'h'`     | signed short       | int               | 2                     |
| `'H'`     | unsigned short     | int               | 2                     |
| `'i'`     | signed int         | int               | 2                     |
| `'I'`     | unsigned int       | int               | 2                     |
| `'l'`     | signed long        | int               | 4                     |
| `'L'`     | unsigned long      | int               | 4                     |
| `'q'`     | signed long long   | int               | 8                     |
| `'Q'`     | unsigned long long | int               | 8                     |
| `'f'`     | float              | float             | 4                     |
| `'d'`     | double             | float             | 8                     |

例如下面我们在一个进程中传入值并对其进行改动，另一个进程输出传入的值，代码如下：

```python
from multiprocessing import Process, Value

def process1(n):
    n.value = "!"
    # pass

def process2(n):
    print('改变后的参数 = {}'.format(n.value))

if __name__ == '__main__':
    # 初始化value
    num = Value('u', "你")
    new_pro1 = Process(target=process1, args=(num,))
    new_pro1.start()
    new_pro1.join()

    new_pro2 = Process(target=process2, args=(num,))
    new_pro2.start()
```

结果：

```
改变后的参数 = !
```

只能传单个的值，字符串都不行。

#### 5.2 Array

上述的 `Value` 类只能传递一个参数，但是 `Array` 可以传递很多的参数，该方法参数如下：

```
Array(typecode_or_type, size_or_initializer, **kwds[, lock])
```

typecode_or_type 参数与上面的相同，同样参照上表，size_or_initializer 如果它是一个整数，那么它确定数组的长度，并且数组将被初始化为0。否则，size_or_initializer 是用于初始化数组的序列，其长度决定数组的长度。kwds 是传递给 typecode_or_type 构造函数的参数，lock 参数与上面的相同。

例如，我们传入一个0数组给一个进程，然后在另一个进程中计算其和，代码如下：

```python
from multiprocessing import Process, Array

def process1(n):
    n[3] = 0
    n[4] = 0

def process2(n):
    # 从队列中得到数据
    print('数组的和为 = {}'.format(sum(n)))

if __name__ == '__main__':
    # 初始化数组
    num = Array('d', range(5))
    new_pro1 = Process(target=process1, args=(num,))
    new_pro1.start()
    new_pro1.join()

    new_pro2 = Process(target=process2, args=(num,))
    new_pro2.start()
```

结果：

```
数组的和为 = 3.0
```

---

### 6、**服务器进程**

由 `Manager()` 返回的管理器对象控制一个服务器进程，该进程保存Python对象并允许其他进程使用代理操作它们。可以用于实现多进程之间的数据共享。

`Manager()` 返回的管理器支持类型： [`list`](https://docs.python.org/zh-cn/3.7/library/stdtypes.html#list) 、 [`dict`](https://docs.python.org/zh-cn/3.7/library/stdtypes.html#dict) 、 [`Namespace`](https://docs.python.org/zh-cn/3.7/library/multiprocessing.html#multiprocessing.managers.Namespace) 、 [`Lock`](https://docs.python.org/zh-cn/3.7/library/multiprocessing.html#multiprocessing.Lock) 、 [`RLock`](https://docs.python.org/zh-cn/3.7/library/multiprocessing.html#multiprocessing.RLock) 、 [`Semaphore`](https://docs.python.org/zh-cn/3.7/library/multiprocessing.html#multiprocessing.Semaphore) 、 [`BoundedSemaphore`](https://docs.python.org/zh-cn/3.7/library/multiprocessing.html#multiprocessing.BoundedSemaphore) 、 [`Condition`](https://docs.python.org/zh-cn/3.7/library/multiprocessing.html#multiprocessing.Condition) 、 [`Event`](https://docs.python.org/zh-cn/3.7/library/multiprocessing.html#multiprocessing.Event) 、 [`Barrier`](https://docs.python.org/zh-cn/3.7/library/multiprocessing.html#multiprocessing.Barrier) 、 [`Queue`](https://docs.python.org/zh-cn/3.7/library/multiprocessing.html#multiprocessing.Queue) 、 [`Value`](https://docs.python.org/zh-cn/3.7/library/multiprocessing.html#multiprocessing.Value) 和 [`Array`](https://docs.python.org/zh-cn/3.7/library/multiprocessing.html#multiprocessing.Array) 。

`shutdown()`终止管理器。

在一个单独的进程中创建运行的管理器。返回值是`SyncMsanager`类型的实例，`SyncManager`类型定义在`multiprocessing.managers`模块中。

示例：

```python
from multiprocessing import Process, Manager

def f(d, l):
    d[1] = '1'
    d['2'] = 2
    d[0.25] = None
    l.reverse()

if __name__ == '__main__':
    with Manager() as manager:
        d = manager.dict()
        l = manager.list(range(10))

        p = Process(target=f, args=(d, l))
        p.start()
        p.join()

        print(d)
        print(l)
```

结果：

```
{1: '1', '2': 2, 0.25: None}
[9, 8, 7, 6, 5, 4, 3, 2, 1, 0]
```



---

### 7、进程池

进程池即可以提供指定数量的进程给用户使用,即当有新的请求提交到进程池中时，如果池未满，则会创建一个新的进程用来执行该请求;反之，如果池中的进程数已经达到规定最大值，那么该请求就会等待，只要池中有进程空闲下来，该请求就能得到执行。

进程池的话Python中有两个方法可以实现，一个是 `multiprocessing `模块自带的 `Pool `类，还有一个是 `concurrent.futures.ProcessPoolExecutor` 进行实现，其中后者的API与线程池的API一模一样，可以参考这里的下面多线程中的线程池来进行学习，这里我介绍下前面一种方式。

该模块的常用方法如下：

```python
Pool([processes[, initializer[, initargs[, maxtasksperchild[, context]]]]])
```

该类一般初始化使用的是 `processes` ，该参数是要使用的工作进程数目。如果 `processes` 为 `None`，则使用 `os.cpu_count()` 返回的值。

```python
apply(func[, args[, kwds]])
```

使用阻塞的方式调用 `func`，必须等待上⼀个进程执行完任务后才能执行下一个进程，了解即可，几乎不用。返回进程执行结束后的返回值。

```python
apply_async(func[, args[, kwds[, callback[, error_callback]]]])
```

使用非阻塞的方式调用 `func`（任务并行执行)，`args` 为传递给 `func` 的参数列表，`kwds` 为传递给 `func` 的关键字参数列表。通过`get()`方法获取任务的结果。

```
terminate()
```

不管任务是否完成，立即终止

```
close()
```

关闭Pool，使其不再接受新的任务。

```
join()
```

主进程阻塞，等待子进程的退出，必须在 `close` 或 `terminate` 之后使用。

下面创建一个容量为4的进程池，并让10个进程都停留三秒输出进程名，代码如下：

```python
import multiprocessing
from multiprocessing import Process, Pool
import time


def proc():
    time.sleep(3)
    print('{} Already Endding >> {}'.format(multiprocessing.current_process().name,
                                            time.strftime('%H:%M:%S', time.localtime(time.time()))))


if __name__ == '__main__':
    # 创建容量为4的进程池
    pool = Pool(4)

    for i in range(10):
        pool.apply_async(proc)
    pool.close()
    # 阻塞主进程，等所有子进程运行完后再通过
    pool.join()
    print('{} Already Endding >> {}'.format(multiprocessing.current_process().name,
                                            time.strftime('%H:%M:%S', time.localtime(time.time()))))
```

结果：

```
SpawnPoolWorker-4 Already Endding >> 15:58:56
SpawnPoolWorker-3 Already Endding >> 15:58:56
SpawnPoolWorker-1 Already Endding >> 15:58:56
SpawnPoolWorker-2 Already Endding >> 15:58:56
SpawnPoolWorker-4 Already Endding >> 15:58:59
SpawnPoolWorker-1 Already Endding >> 15:58:59SpawnPoolWorker-3 Already Endding >> 15:58:59

SpawnPoolWorker-2 Already Endding >> 15:58:59
SpawnPoolWorker-3 Already Endding >> 15:59:02
SpawnPoolWorker-4 Already Endding >> 15:59:02
MainProcess Already Endding >> 15:59:03
```

---

### 9、库方法

| multiprocessing库                    | 功能                                                         |
| ------------------------------------ | ------------------------------------------------------------ |
| `multiprocessing.active_children()`  | 返回当前进程存活的子进程的列表。                             |
| `multiprocessing.cpu_count()`        | 返回系统的CPU数量。                                          |
| ``multiprocessing.current_process()` | 返回与当前进程相对应的 [`Process`](https://docs.python.org/zh-cn/3.7/library/multiprocessing.html#multiprocessing.Process) 对象。 |



---

## 多线程

### 1、创建线程

**（1）通过 threading.Thread () 创建**

```python
thread.Thread(group=Nore,targt=None,args=(),kwargs={},*,daemon=None)
```

参数解释：

~group：必须为None，于ThreadGroup类相关，一般不使用。

~target：线程调用的对象，就是目标函数。

~name：为线程起这个名字。默认是Tread-x，x是序号，由1开始，第一个创建的线程名字就是Tread-1。

~args：为目标函数传递关键字参数，字典。

~daemon：用来设置线程是否随主线程退出而退出。

示例：

```python
import threading
def test (x,y):
 for i in range(x,y):
   print(i)
thread1 = threading.Thread(name='t1',target= test,args=(1,10))
thread2 = threading.Thread(name='t2',target= test,args=(11,20))
thread1.start()   #启动线程1
thread2.start()   #启动线程2
```

输出：

```
1
2
113
4

5
126
7

8
9
13
14
15
16
17
18
19
```

解释：两个程序会并发运行，所以结果不一定每次都是顺序的1~10，这是根据CPU给两个线程风马分配的时间片段来决定。可以看到每次结果都不同。

**（2）通过继承 threading.Thread 类的继承**

threading.Thread是一个类，可以继承它。

示例：

```python
import threading
class mythread(threading.Thread):
  def run(self):
    for i in range(1,10):
      print(i)
thread1 = mythread()
thread2 = mythread()
thread1.start()
thread2.start()
```

输出：

```python
1
2
3
4
5
6
7
8
9
1
2
3
4
5
6
7
8
9
```

解释：自定义一个类继承threading.Thread,然后重写父类的run方法，线程启动时（执行start（））会自动执行该方法。

---

### 2、主线程、守护线程

在python中，主线程是第一个启动的线程。

~父线程:如果启动线程A中启动了一个线程B，A就是B的父线程。

~子线程：B就是A的子线程。

创建线程时有一个damon属性，用它来判断主线程。当daemon设置False时，线程不会随主线程退出而退出，主线程会一直等着子线程执行完;。当daemon设置True时，线程会随主线程退出而退出，主线程结束其他的子线程会强制退出。

使用daemon注意：

~daemon属性必须在start( )之前设置，否则会引发RuntimeError异常

~每个线程都由daemon属性，可以显示设置也可以不设置，不设置则取默认值None

~如果子子线程不设置daemon属性，就取当前线程的daemon来设置它。子子线程继承子线程的daemon值，作用和设置None一样。

~从主线程创建的所有线程不设置daemon属性，则默认都是`daemon=False`。

`daemon=True` 的线程为守护线程

示例：

```python
import time
import threading
def test():
 time.sleep(10)
 for i in range(10):
  print(i)
thread1 = threading.Thread(target=test,daemon=False)
thread1.start()
print('主线程完成了')
```

输出：

```
主线程完成了
0
1
2
3
4
5
6
7
8
9
```

解释：当主线程运行完毕输出完之后，等待一下后输出0~9。如果将daemon=False该为daemon=True，则不会运行for i in range(10)语句。

---

### 3、阻塞线程

一个线程中调用另一个线程的join方法，调用者被阻塞，直到调用线程被终止。

语法形式：

```python
join(timeout-=None)
```

timeout 参数指定调用者等待多久，没有设置时，就一直等待被调用线程结束被调用线程结束。其中，一个线程可以被join多次调用。

示例：

```python
import time
import threading


def test():
    time.sleep(5)
    for i in range(10):
        print(i)


thread1 = threading.Thread(target=test)
thread1.start()
thread1.join()
print('主线程完成了')
```

输出：

```
0
1
2
3
4
5
6
7
8
9
主线程完成了
```

解释：在`thread1.start()`后加`thread1.join()`添加`join`方法，输出时，主线程就会等待输出完0~9后再执行自己的print输出。

---

### 4、线程结束问题

（1）线程的结束一般依靠线程函数的自然结束，一般不是循环操作；

（2）可以线程中任务结束后，在线程函数中调用`thread.exit()`，他抛出SystemExit exception，达到退出线程的目的；

（3）利用一个全局变量flag来控制是否在线程函数中调用`thread.exit()`。

（4）实际上在真正的编程中大部分情况下可能是循环操作，比如网络编程中循环监听端口。一般用一个全局变量flag控制循环执行，函数外设置flag为false结束线程。

​    当一个线程结束计算，它就退出了。线程可以调用`thread.exit()`之类的退出函数，也可以使用Python退出进程的标准方法，如`sys.exit()`或抛出一个`SystemExit`异常等。不过，不可以直接杀掉Kill一个线程。

----

### 5、线程同步

threading模块所提供的锁类型：

- Lock：互斥锁
- RLock：可重入锁，使单一进程再次获得已持有的锁(递归锁)
- Condition：条件锁，使得一个线程等待另一个线程满足特定条件，比如改变状态或某个值。
- Semaphore：信号锁。为线程间共享的有限资源提供一个”计数器”，如果没有可用资源则会被阻塞。
- Event：事件锁，任意数量的线程等待某个事件的发生，在该事件发生后所有线程被激活
- Timer：一种计时器
- Barrier：Python3.2新增的“阻碍”类，必须达到指定数量的线程后才可以继续执行。

#### 5.1 线程锁

如果多个线程共同对某个数据修改，则可能出现不可预料的结果，为了保证数据的正确性，需要对多个线程进行同步。通常锁还与**try/finally**及**with**一起用，为了保证锁一定会被释放，如果发生exception，锁不释放就会出现问题。

多线程和多进程最大的不同在于，多进程中，同一个变量，各自有一份拷贝存在于每个进程中，互不影响，而多线程中，所有变量都由所有线程共享所在进程的资源和数据，所以，任何一个变量都可以被任何一个线程修改，因此，线程之间共享数据最大的危险在于多个线程同时改一个变量，把内容给改乱了。

**Condition是在Lock/RLock的基础上再次包装而成**，而Semaphore的原理和[操作系统](https://link.juejin.im/?target=http%3A%2F%2Flib.csdn.net%2Fbase%2Foperatingsystem)的PV操作一致。

使用Thread对象的**Lock和Rlock**可以实现简单的线程同步，这两个对象都有**acquire方法（请求锁）和release（释放锁）**方法，对于那些需要每次只允许一个线程操作的数据，可以将其操作放到acquire和release方法之间。如下：

```python
import threading
import time


class myThread(threading.Thread):
    def __init__(self, threadID, name, counter):
        threading.Thread.__init__(self)
        self.threadID = threadID
        self.name = name
        self.counter = counter

    def run(self):
        print("Starting " + self.name)
        # 获得锁，成功获得锁定后返回True
        # 可选的timeout参数不填时将一直阻塞直到获得锁定
        # 否则超时后将返回False
        threadLock.acquire()
        print_time(self.name, self.counter, 3)
        # 释放锁
        threadLock.release()


def print_time(threadName, delay, counter):
    while counter:
        time.sleep(delay)
        print("%s: %s" % (threadName, time.ctime(time.time())))
        counter -= 1


threadLock = threading.Lock()
threads = []

# 创建新线程
thread1 = myThread(1, "Thread-1", 1)
thread2 = myThread(2, "Thread-2", 2)

# 开启新线程
thread1.start()
thread2.start()

# 添加线程到线程列表
threads.append(thread1)
threads.append(thread2)

# 等待所有线程完成
for t in threads:
    t.join()
print("Exiting Main Thread")
```

**Lock (互斥锁Mutex)。**互斥锁是一种**独占锁**，同一时刻只有一个线程可以访问共享的数据。使用很简单，初始化锁对象，然后**将锁当做参数传递给任务函数或者利用全局对象传递参数**，在任务中加锁，使用后释放锁。

 重入锁（Re-Entrant Lock）。 可重入锁对象。使单线程可以再次获得已经获得了的锁（递归锁定）。RLock允许在同一线程中被多次acquire。而Lock却不允许这种情况。否则会出现死循环，程序不知道解哪一把锁。注意：如果使用RLock，那么acquire和release必须成对出现，即调用了n次acquire，必须调用n次的release才能真正释放所占用的锁。

RLock的使用方法和Lock一模一样，只不过它支持重入锁。该锁对象内部维护着一个Lock和一个counter对象。counter对象记录了acquire的次数，使得资源可以被多次require。最后，当所有RLock被release后，其他线程才能获取资源。在同一个线程中，RLock.acquire()可以被多次调用，利用该特性，可以解决部分死锁问题。

也就是同一个线程可以获得多个锁，利用计数器来实现，然后逐步清除即可。锁没有释放，也可以继续请求锁，不会阻塞。但是RLock是线程级别的，在哪个线程acquire的，就需要在这个线程release，其它线程无法release。也就是说RLock无法跨线程。需要跨线程就得使用Lock。从而避免引起脏数据问题。

#### 5.2 信号量

Threading 模块包含对其他功能的支持。例如，可以创建信号量（Semaphore），这是计算机科学中最古老的同步原语之一。基本上，一个信号量管理一个内置的计数器。当你调用 acquire 时计数器就会递减，相反当你调用 release 时就会递增。根据其设计，计数器的值无法小于零，所以如果正好在计数器为零时调用 acquire 方法，该方法将阻塞线程。通常使用信号量时都会初始化一个大于零的值，如 semaphore = threading.Semaphore(2)。

示例：

```python
import threading
import time


def run(n, se):
    se.acquire()
    print("run the thread: %s" % n)
    time.sleep(1)
    se.release()


# 设置允许5个线程同时运行
semaphore = threading.BoundedSemaphore(5)
for i in range(20):
    t = threading.Thread(target=run, args=(i, semaphore))
    t.start()
```

运行后，可以看到5个一批的线程被放行。

​    mutex 互斥锁 是semaphore的一种特殊情况（n=1时）。也就是说，完全可以用后者替代前者。但是，因为mutex较为简单，且效率高，所以在必须保证资源独占的情况下，还是采用这种设计。

#### **5.3 Event**事件

另一个非常有用的同步工具就是事件（**Event**）。它允许你使用**信号（signal）**实现线程通信。Python提供了Event对象用于**线程间通信**，它**是由线程设置的信号标志**，如果信号标志为真，则其他线程等待直到**信号清除**。

Event对象实现了简单的线程通信机制，它提供了**设置信号，清除信号，等待**等用于实现线程间的通信。

```python
event = threading.Event() # 创建一个event
```

事件线程锁的运行机制：全局定义了一个Flag，如果Flag的值为False，那么当程序执行wait()方法时就会阻塞，如果Flag值为True，线程不再阻塞。这种锁，类似交通红绿灯（默认是红灯），它属于在红灯的时候一次性阻挡所有线程，在绿灯的时候，**一次性放行所有**排队中的线程。 

**1 设置信号**

```
event.set()
```

使用Event的`set()`方法可以**设置Event对象内部的信号标志为真**。Event对象提供了`isSet()`方法来判断其内部信号标志的状态。当使用event对象的set()方法后，`isSet()`方法返回真

**2 清除信号**

```
event.clear()
```

使用Event对象的`clear()`方法可以**清除Event对象内部的信号标志**，即将其设为假，当使用Event的clear方法后，`isSet()`方法返回假。

**3 等待**

```
event.wait()
```

Event对象wait的方法**只有在内部信号为真的时候才会很快的执行并完成返回**。当Event对象的内部信号标志为假时，则**wait方法一直等待到其为真时才返回**。也就是说必须set信号标志位真。

**示例：**

```python
import threading


def do(event):
    print('start')
    event.wait()
    print('execute')


event_obj = threading.Event()
for i in range(10):
    t = threading.Thread(target=do, args=(event_obj,))
    t.start()

event_obj.clear()
inp = input('输入内容:')
if inp == 'true':
    event_obj.set()
```

输出：

```
start
start
start
start
start
start
start
start
start
start输入内容:
true
executeexecute
executeexecuteexecuteexecuteexecute

executeexecute


execute
```

#### 5.4 条件Condition

Condition称作条件锁，依然是通过acquire()/release()加锁解锁。

wait([timeout])方法将使线程进入Condition的等待池等待通知，并释放锁。使用前线程必须已获得锁定，否则将抛出异常。

notify()方法将从等待池挑选一个线程并通知，收到通知的线程将自动调用acquire()尝试获得锁定（进入锁定池），其他线程仍然在等待池中。调用这个方法不会释放锁定。使用前线程必须已获得锁定，否则将抛出异常。

notifyAll()方法将通知等待池中所有的线程，这些线程都将进入锁定池尝试获得锁定。调用这个方法不会释放锁定。使用前线程必须已获得锁定，否则将抛出异常。

#### **5.5 Barrier**

最后，在 Python 3.2 中加入了 Barrier 对象。Barrier 是管理线程池中的同步原语，在线程池中多条线程需要相互等待对方。如果要传递 barrier，每一条线程都要调用 wait() 方法，在其他线程调用该方法之前线程将会阻塞。全部调用之后将会同时释放所有线程。

#### 5.6 定时器Timer

定时器Timer类是threading模块中的一个小工具，用于指定n秒后执行某操作。

```python
from threading import Timer
 
def hello():
    print("hello, world")
 
# 表示1秒后执行hello函数
t = Timer(1, hello)
t.start()
```

#### 5.7 创建线程本地数据

我们知道进程之间数据互不干扰，而进程内的线程共享进程数据、资源和地址空间等。有些场景下，我们希望每个线程，都有自己独立的数据，他们使用同一个变量，但是在每个线程内的数据都是独立的互不干扰的，类似于进程中的数据。

我们可以使用`threading.local()` 相当于创建线程局部变量来实现：
示例：

```python
import threading

L = threading.local()
L.num = 1
# 此时操作的是我们当前主线程的threading.local()对象，输出结果为1
print(L.num)


def f():
    L.num = 5  # 重新赋值，相当于新定义的变量
    # 这里可以成功的输出5
    print(L.num)


# 创建一个子线程，去调用f()，看能否访问主线程中定义的L.num
t = threading.Thread(target=f)
t.start()
# 主线程中的L.num依然是1，没有发生任何改变
print(L.num)
```

输出：

```
1
51
```

由此可见，threading.local()创建的对象中的属性，是对于每个线程独立存在的，它们相互之间无法干扰，我们称它为线程本地数据。

全局变量L就是一个ThreadLocal对象，每个Thread对它都可以读写student属性，但互不影响。你可以把L看成全局变量，但每个属性如L.num都是线程的局部变量，可以任意读写而互不干扰，也不用管理锁的问题，ThreadLocal内部会处理。

可以理解为全局变量L是一个dict，不但可以用L.num，还可以绑定其他变量，如L.num1等等。

ThreadLocal最常用的地方就是为每个线程绑定一个数据库连接，HTTP请求，用户身份信息等，这样一个线程的所有调用到的处理函数都可以非常方便地访问这些资源。

---

### 6、线程通信

Python的Queue模块中提供了同步的、线程安全的队列类，包括FIFO（先入先出)队列Queue，LIFO（后入先出）队列LifoQueue，和优先级队列PriorityQueue。这些队列都实现了锁原语，能够在多线程中直接使用。可以使用队列来实现线程间的同步。用于信息和资源共享。

凡是符合该种结构的多线程通信过程我们称之为生产者-消费者模型（应届生面试常问）。

| queue.Queue                     | 作用                                                         |
| ------------------------------- | ------------------------------------------------------------ |
| `Queue.qsize()`                 | 返回队列的大小                                               |
| `Queue.empty()`                 | 如果队列为空，返回True,反之False                             |
| `Queue.full()`                  | 如果队列满了，返回True,反之False                             |
| `Queue.full`                    | 与 maxsize 大小对应（什么玩意儿？）                          |
| `Queue.get([block[, timeout]])` | 获取队列，timeout等待时间                                    |
| `Queue.get_nowait()`            | 相当Queue.get(False)                                         |
| `Queue.put(item[, timeout])`    | 写入队列，timeout等待时间                                    |
| `Queue.put_nowait(item)`        | 相当Queue.put(item, False)                                   |
| `Queue.task_done()`             | 在完成一项工作之后，Queue.task_done()函数向任务已经完成的队列发送一个信号 |
| `Queue.join()`                  | 实际上意味着等到队列为空，再执行别的操作                     |

示例：

```python
import threading
import time
from queue import Queue

exitFlag = 0


class myThread(threading.Thread):
    def __init__(self, threadID, name, q):
        threading.Thread.__init__(self)
        self.threadID = threadID
        self.name = name
        self.q = q

    def run(self):
        print("Starting " + self.name)
        process_data(self.name, self.q)
        print("Exiting " + self.name)


def process_data(threadName, q):
    while not exitFlag:
        queueLock.acquire()
        if not workQueue.empty():
            data = q.get()
            queueLock.release()
            print("%s processing %s" % (threadName, data))
        else:
            queueLock.release()
        time.sleep(1)


threadList = ["Thread-1", "Thread-2", "Thread-3"]
nameList = ["One", "Two", "Three", "Four", "Five"]
queueLock = threading.Lock()
workQueue = Queue(10)
threads = []
threadID = 1

# 创建新线程
for tName in threadList:
    thread = myThread(threadID, tName, workQueue)
    thread.start()
    threads.append(thread)
    threadID += 1

# 填充队列
queueLock.acquire()
for word in nameList:
    workQueue.put(word)
queueLock.release()

# 等待队列清空
while not workQueue.empty():
    pass

# 通知线程是时候退出
exitFlag = 1

# 等待所有线程完成
for t in threads:
    t.join()
print("Exiting Main Thread")
```

输出：

```
Starting Thread-1
Starting Thread-2
Starting Thread-3
Thread-1 processing OneThread-3 processing Two

Thread-2 processing Three
Thread-3 processing Four
Thread-1 processing Five
Exiting Thread-2
Exiting Thread-1Exiting Thread-3

Exiting Main Thread
```

---

### 7、线程池

线程池的基类是 concurrent.futures 模块中的 Executor，Executor 提供了两个子类，即 ThreadPoolExecutor 和 ProcessPoolExecutor，其中 ThreadPoolExecutor 用于创建线程池，而 ProcessPoolExecutor 用于创建进程池。

如果使用线程池/进程池来管理并发编程，那么只要将相应的 task 函数提交给线程池/进程池，剩下的事情就由线程池/进程池来搞定。

Exectuor 提供了如下常用方法：

- `submit(fn, *args, **kwargs)`：将 fn 函数提交给线程池。*args 代表传给 fn 函数的参数，*kwargs 代表以关键字参数的形式为 fn 函数传入参数。
- `map(func, *iterables, timeout=None, chunksize=1)`：该函数类似于全局函数 map(func, *iterables)，只是该函数将会启动多个线程，以异步方式立即对 iterables 执行 map 处理。
- `shutdown(wait=True)`：关闭线程池。

程序将 task 函数提交（submit）给线程池后，submit 方法会返回一个 Future 对象，Future 类主要用于获取线程任务函数的返回值。由于线程任务会在新线程中以异步方式执行，因此，线程执行的函数相当于一个“将来完成”的任务，所以 Python 使用 Future 来代表。

Future 提供了如下方法：

- `cancel()`：取消该 Future 代表的线程任务。如果该任务正在执行，不可取消，则该方法返回 False；否则，程序会取消该任务，并返回 True。
- `cancelled()`：返回 Future 代表的线程任务是否被成功取消。
- `running()`：如果该 Future 代表的线程任务正在执行、不可被取消，该方法返回 True。
- `done()`：如果该 Funture 代表的线程任务被成功取消或执行完成，则该方法返回 True。
- `result(timeout=None)`：获取该 Future 代表的线程任务最后返回的结果。如果 Future 代表的线程任务还未完成，该方法将会阻塞当前线程，其中 timeout 参数指定最多阻塞多少秒。
- `exception(timeout=None)`：获取该 Future 代表的线程任务所引发的异常。如果该任务成功完成，没有异常，则该方法返回 None。
- `add_done_callback(fn)`：为该 Future 代表的线程任务注册一个“回调函数”，当该任务成功完成时，程序会自动触发该 fn 函数。

在用完一个线程池后，应该调用该线程池的 shutdown() 方法，该方法将启动线程池的关闭序列。调用 shutdown() 方法后的线程池不再接收新任务，但会将以前所有的已提交任务执行完成。当线程池中的所有任务都执行完成后，该线程池中的所有线程都会死亡。

使用线程池来执行线程任务的步骤如下：

- 调用 ThreadPoolExecutor 类的构造器创建一个线程池。
- 定义一个普通函数作为线程任务。
- 调用 ThreadPoolExecutor 对象的 submit() 方法来提交线程任务。
- 当不想提交任何任务时，调用 ThreadPoolExecutor 对象的 shutdown() 方法来关闭线程池。

#### 1.使用 submit 方法提交任务

从Python3.2开始，标准库为我们提供了`concurrent.futures` 模块，它提供了 `ThreadPoolExecutor` (线程池)和 `ProcessPoolExecutor` (进程池)两个类。

相比 `threading` 等模块，该模块通过 submit 返回的是一个 future 对象，它是一个未来可期的对象，通过它可以获取某一个线程执行的状态或者某一个任务执行的状态及返回值：

1. 主线程可以获取某一个线程（或者任务的）的状态，以及返回值。
2. 当一个线程完成的时候，主线程能够立即知道。
3. `submit(fn, *args, **kwargs)`：将 fn 函数提交给线程池。*args 代表传给 fn 函数的参数，*kwargs 代表以关键字参数的形式为 fn 函数传入参数。

示例：

```python
import threading
import time
from concurrent.futures import ThreadPoolExecutor


def test(value1, value2=None):
    print("%s threading is printed %s, %s" % (threading.current_thread().name, value1, value2))
    time.sleep(2)
    return 'finished'


def test_result(future):
    print(future.result())


if __name__ == "__main__":
    threadPool = ThreadPoolExecutor(max_workers=3, thread_name_prefix="test_")#创建线程池
    for i in range(0, 4):
        future = threadPool.submit(test, i, i + 1)	# 提交任务到线程池
        print(future.result())

    threadPool.shutdown(wait=True)	# 关闭线程池
```

​	输出：

```python
test__0 threading is printed 0, 1
finished
test__0 threading is printed 1, 2
finished
test__0 threading is printed 2, 3
finished
test__0 threading is printed 3, 4
finished
```

#### 2.使用 map 方法提交任务

map 方法是对序列中每一个元素都执行 action 方法，主要有两个特点：

1. 不需要将任务submit到线程池
2. 返回结果的顺序和元素的顺序相同，即使子线程先返回也不会获取结果

```
map(fn, *iterables, timeout=None)
```

fn： 第一个参数 fn 是需要线程执行的函数；

iterables：第二个参数接受一个可迭代对象；

timeout： 第三个参数 timeout 跟 wait() 的 timeout 一样，但由于 map 是返回线程执行的结果，如果 timeout小于线程执行时间会抛异常 TimeoutError。

示例：

```python
import threading
import time
from concurrent.futures import ThreadPoolExecutor


def test(value1, value2=None):
    print("%s threading is printed %s, %s" % (threading.current_thread().name, value1, value2))
    time.sleep(2)
    return threading.current_thread().name + '  finished'


if __name__ == "__main__":
    threadPool = ThreadPoolExecutor(max_workers=4, thread_name_prefix="test_")
    for i in range(0, 4):
        for result in threadPool.map(test, [i], [i + 1]):
            print(result)
    threadPool.shutdown(wait=True)
```

输出：

```
test__0 threading is printed 0, 1
test__0  finished
test__0 threading is printed 1, 2
test__0  finished
test__0 threading is printed 2, 3
test__0  finished
test__0 threading is printed 3, 4
test__0  finished
```

#### 3.使用上下文管理器

可以通过 `with` 关键字来管理线程池，当线程池任务完成之后自动关闭线程池。

示例：

```python
import time
from concurrent.futures import ThreadPoolExecutor


def action(second):
    print(second)
    time.sleep(second)
    return second


lists = [4, 5, 2, 3]
all_task = []
with ThreadPoolExecutor(max_workers=2) as pool:
    for second in lists:
        all_task.append(pool.submit(action, second))

    result = [i.result() for i in all_task]
    print(f"result:{result}")
```

输出：

```
4
5
2
3
result:[4, 5, 2, 3]
```

#### 4.等待

在需要返回值的场景下，主线程需要等到所有子线程返回再进行下一步，阻塞在当前。比如下载图片统一保存，这时就需要在主线程中一直等待，使用`wait`方法完成。

```python
wait(fs, timeout=None, return_when=ALL_COMPLETED)
```

wait 接受三个参数：

fs: 表示需要执行的序列

timeout: 等待的最大时间，如果超过这个时间即使线程未执行完成也将返回

return_when：表示wait返回结果的条件，默认为 `ALL_COMPLETED` 全部执行完成再返回，可选 `FIRST_COMPLETED`

示例：

```python
import time
from concurrent.futures import ThreadPoolExecutor, wait, ALL_COMPLETED


def action(second):
    print(second)
    time.sleep(second)
    return second


lists = [4, 5, 2, 3]
all_task = []
with ThreadPoolExecutor(max_workers=2) as pool:
    for second in lists:
        all_task.append(pool.submit(action, second))

    # 主线程等待所有子线程完成
    wait(all_task, return_when=ALL_COMPLETED)
    print("----complete-----")
```

输出：

```
4
5
2
3
----complete-----
```

#### 5.获取执行结果

**（1）阻塞线程获取每一个结果**

示例：

```python
import threading
import time
from concurrent.futures import ThreadPoolExecutor


def test(value1, value2=None):
    print("%s threading is printed %s, %s" % (threading.current_thread().name, value1, value2))
    time.sleep(2)
    return 'finished'


def test_result(future):
    print(future.result())


if __name__ == "__main__":
    threadPool = ThreadPoolExecutor(max_workers=2, thread_name_prefix="test_")

    for i in range(0, 2):
        future = threadPool.submit(test, i, i + 1)
        print(future.result())
    threadPool.shutdown(wait=True)
    print('main finished')
```

输出：

```
test__0 threading is printed 0, 1
finished
test__0 threading is printed 1, 2
finished
main finished
```

**（2）add_done_callback() 回调函数来获取返回值**

前面程序调用了 Future 的 result() 方法来获取线程任务的运回值，但该方法会阻塞当前主线程，只有等到钱程任务完成后，result() 方法的阻塞才会被解除。

如果程序不希望直接调用 result() 方法阻塞线程，则可通过 Future 的 add_done_callback() 方法来添加回调函数，该回调函数形如 fn(future)。当线程任务完成后，程序会自动触发该回调函数，并将对应的 Future 对象作为参数传给该回调函数。直接调用result函数结果

示例：

```python
import threading
import time
from concurrent.futures import ThreadPoolExecutor


def test(value1, value2=None):
    print("%s threading is printed %s, %s" % (threading.current_thread().name, value1, value2))
    time.sleep(2)
    return threading.current_thread().name + ' finished'


future_list = []


def test_result(future):
    # print(future.result())
    future_list.append(future.result())


if __name__ == "__main__":
    threadPool = ThreadPoolExecutor(max_workers=2, thread_name_prefix="test_")
    for i in range(0, 2):
        future = threadPool.submit(test, i, i + 1)
        future.add_done_callback(test_result)
    threadPool.shutdown(wait=True)
    print('main finished')
    for result in future_list:
        print(result)
```

输出：

```python
test__0 threading is printed 0, 1
test__1 threading is printed 1, 2
main finished
test__1 finished
test__0 finished
```

**（3）使用 futures.wait 来全局等待**

示例：

```python
import threading
import time
from concurrent import futures
from concurrent.futures import ThreadPoolExecutor


def test(value1, value2=None):
    print("%s threading is printed %s, %s" % (threading.current_thread().name, value1, value2))
    time.sleep(2)
    return threading.current_thread().name + '  finished'


if __name__ == "__main__":
    feature_list = []
    threadPool = ThreadPoolExecutor(max_workers=2, thread_name_prefix="test_")
    for i in range(0, 2):
        future = threadPool.submit(test, i, i + 1)
        feature_list.append(future)
    # 等待所有线程运行完毕
    futures.wait(feature_list)
    threadPool.shutdown(wait=True)
    print('-----------')
    # 打印结果
    for feature in feature_list:
        result = feature.result()
        print(result)
```

输出：

```
test__0 threading is printed 0, 1
test__1 threading is printed 1, 2
-----------
test__0  finished
test__1  finished
```

#### 6.处理submit非阻塞导致的所有任务会一次性创建的问题

`submit()`是非阻塞的，提交任务后立即返回。也就是说，还是假设我们有100个任务用10个线程去处理，那么这100个任务基本就是一下就创建完成。当然线程池自己会组织好这100个任务，慢慢地让这10个线程去处理。

这种机制在100个任务下还没什么大的影响，但如果我们有100万个任务呢，100万个任务同时创建，100万个任务的信息堆在内存中，内存消耗就是很大的问题了。

所以当任务量很大、或者任务的参数很大时就要注意和处理submit非阻塞可能会导致的内存消耗问题。

处理方法如下：

示例：

```python
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor  # 线程池，进程池
import threading
import time


class TestClass():
    def __init__(self):
        # 线程池+线程同步改造添加代码处1/5： 定义锁和线程池
        # 我们第二大节中说的是锁不能在线程类内部实例化，这个是调用类不是线程类，所以可以在这里实例化
        self.threadLock = threading.Lock()
        # 定义2个线程的线程池
        self.thread_pool = ThreadPoolExecutor(2)
        # 定义2个进程的进程池。进程池没用写在这里只想表示进程池的用法和线程池基本一样
        # self.process_pool = ProcessPoolExecutor(2)
        pass

    def main_logic(self):
        for i in range(6):
            # 线程池+线程同步改造添加代码处3/5： 注释掉原先直接调的do_something的形式，改成通过添加的中间函数调用的形式
            # self.do_something(i)
            self.call_do_something(i)
        pass

    # 线程池+线程同步改造添加代码处2/5： 添加一个通过线程池调用do_something的中间方法。参数与do_something一致
    def call_do_something(self, para):
        # 控制未完成任务数添加代码处1/3：定义一个变量，记录当前任务列表。规范写法是在__init__中定义我为代码信中放在这里
        try:
            self.task_handler_list
        except:
            self.task_handler_list = []
        # 控制未完成任务数添加代码处2/3：提交任务时把任务句柄记录到上边定义的列表中
        task_handler = self.thread_pool.submit(self.do_something, para)
        self.task_handler_list.append(task_handler)
        # 控制未完成任务数添加代码处3/3：当未完成任务数不多于线程的2倍时才允许此任务返回
        while True:
            # 我们可能听说过使用as_completed()可以获取执行完成的任务列表，但实际发现as_completed是阻塞的他要等待任务响应他的询问
            # 所以并不推荐使用以下形式来获取未执行完成的任务列表
            # task_handler_list = list(set(task_handler_list) - set(concurrent.futures.as_completed(task_handler_list)))
            # 将已完成的任务移出列表
            for task_handler_tmp in self.task_handler_list:
                if task_handler_tmp.done():
                    self.task_handler_list.remove(task_handler_tmp)
            # 如果未完成的任务已多于线程数的两倍那么先停一下，先不要再增加任务，因为几万个ip一把放到内存中是个很大的消耗
            if len(self.task_handler_list) > 2 * 2:
                print("unfinished task is more than double thread_count, will be wait a seconds.")
                # 睡眠多久看自己需要，我这设2秒
                time.sleep(2)
            else:
                return True

    def do_something(self, para):
        thread_name = threading.current_thread().name
        # 线程池+线程同步改造添加代码处4/5： 获取锁
        self.threadLock.acquire()
        print(f"this is thread : {thread_name}")
        print(f"the parameter value is  : {para}")
        # 线程池+线程同步改造添加代码处5/5： 释放锁
        self.threadLock.release()
        time.sleep(1)
        pass


if __name__ == "__main__":
    obj = TestClass()
    obj.main_logic()
```

输出：

```
this is thread : ThreadPoolExecutor-0_0
the parameter value is  : 0
this is thread : ThreadPoolExecutor-0_1unfinished task is more than double thread_count, will be wait a seconds.

the parameter value is  : 1
this is thread : ThreadPoolExecutor-0_1
the parameter value is  : 2
this is thread : ThreadPoolExecutor-0_0
the parameter value is  : 3
this is thread : ThreadPoolExecutor-0_1
the parameter value is  : 4
this is thread : ThreadPoolExecutor-0_0
the parameter value is  : 5
```



---

### 8、库方法

| threading.Thread                                             | 作用                                                         |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| `Thread(group=Nore,targt=None,args=(),kwargs={},*,daemon=None)` | `group`：必须为None，于ThreadGroup类相关，一般不使用。  `target`：线程调用的对象，就是目标函数。  `name`：为线程起这个名字。默认是Tread-x，x是序号，由1开始，第一个创建的线程名字就是Tread-1。  `args`：为目标函数传递关键字参数，字典。  `daemon`：用来设置线程是否随主线程退出而退出。 |
| `run()`                                                      | 用以表示线程活动的方法                                       |
| `start()`                                                    | 启动线程                                                     |
| `join()`                                                     | 等待至线程终止                                               |
| `isAlive()`                                                  | 返回线程是否活动的                                           |
| `getName()`                                                  | 返回线程名称                                                 |
| `setName()`                                                  | 设置线程名称                                                 |

| queue.Queue                     | 作用                                                         |
| ------------------------------- | ------------------------------------------------------------ |
| `Queue.qsize()`                 | 返回队列的大小                                               |
| `Queue.empty()`                 | 如果队列为空，返回True,反之False                             |
| `Queue.full()`                  | 如果队列满了，返回True,反之False                             |
| `Queue.full`                    | 与 maxsize 大小对应（什么玩意儿？）                          |
| `Queue.get([block[, timeout]])` | 获取队列，timeout等待时间                                    |
| `Queue.get_nowait()`            | 相当Queue.get(False)                                         |
| `Queue.put(item[, timeout])`    | 写入队列，timeout等待时间                                    |
| `Queue.put_nowait(item)`        | 相当Queue.put(item, False)                                   |
| `Queue.task_done()`             | 在完成一项工作之后，Queue.task_done()函数向任务已经完成的队列发送一个信号 |
| `Queue.join()`                  | 实际上意味着等到队列为空，再执行别的操作                     |

---

### 9、总结

（1）thread模块创建多线程有一种方法。threading模块创建多线程有两种方法：继承Thread类和直接利用Thread类。

（2）锁的好处就是确保了某段关键代码只能由一个线程从头到尾完整地执行，坏处当然也很多，首先是阻止了多线程并发执行，包含锁的某段代码实际上只能以单线程模式执行，效率就大大地下降了。其次，由于可以存在多个锁，不同的线程持有不同的锁，并试图获取对方持有的锁时，可能会造成死锁，导致多个线程全部挂起，既不能执行，也无法结束，只能靠操作系统强制终止。

（3）默认子线程非守护线程，也就是各个子线程和主线程同时执行，各自执行互不干扰。最后等待子线程执行完成，主线程才退出（此时主线程有可能任务执行完，但是没有退出）。而join函数的不同点是，在运行join函数的地方主线程阻塞，后面的任务不执行，等待子线程执行完成之后，主线程继续执行然后退出（如果所有子线程都执行完毕，否则在主线程执行完任务之后还需要等待其他子线程执行完毕后才能退出）。

（4）锁可以去with等语句共用，比如 with lock，即可实现锁的请求与释放。

（5）当我们需要编写并发爬虫等IO密集型的程序时，应该选用多线程或者协程（亲测差距不是特别明显）；当我们需要科学计算，设计CPU密集型程序，应该选用多进程。当然以上结论的前提是，不做分布式，只在一台服务器上测试。

---

## 参考文献

### 多进程

https://blog.csdn.net/ifhuke/article/details/128642625

https://www.jb51.net/python/326076w9d.htm

https://docs.python.org/zh-cn/3.7/library/multiprocessing.html

### 多线程

https://gitcode.csdn.net/6628ae239ab37021bfb0b0a3.html?dp_token=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpZCI6NTgxMzA2LCJleHAiOjE3Mjc1OTk1MzQsImlhdCI6MTcyNjk5NDczNCwidXNlcm5hbWUiOiJxcV81OTc2MTkxMyJ9.ir-_wWH9Dfc6dZoAUYcFk7eAjuRCpm7KJczNIpYYFgg&spm=1001.2101.3001.6650.6&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7Eactivity-6-125021831-blog-86511571.235%5Ev43%5Epc_blog_bottom_relevance_base8&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7Eactivity-6-125021831-blog-86511571.235%5Ev43%5Epc_blog_bottom_relevance_base8&utm_relevant_index=13

https://blog.csdn.net/answer3lin/article/details/86511571

https://www.cnblogs.com/alex-oos/p/18395921

https://blog.51cto.com/u_14246112/12088404

https://blog.csdn.net/qq_43745578/article/details/128754615?spm=1001.2101.3001.6650.1&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ECtr-1-128754615-blog-137108894.235%5Ev43%5Epc_blog_bottom_relevance_base8&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ECtr-1-128754615-blog-137108894.235%5Ev43%5Epc_blog_bottom_relevance_base8&utm_relevant_index=2

threading模块的官方文档：https://docs.python.org/zh-cn/3/library/threading.html#?login=from_csdn